neural network machine learning wikipedia move sidebar hide main pagecontentscurrent eventsrandom articleabout wikipediacontact us contribute helplearn editcommunity portalrecent changesupload filespecial pages donate personal donate pages logged editors learn contributionstalk contents move sidebar hide top training history toggle history subsection early work deep learning breakthroughs backpropagation convolutional neural networks recurrent neural networks deep learning models toggle models subsection artificial neurons organization hyperparameter learning learning rate cost function backpropagation learning paradigms supervised learning unsupervised learning reinforcement learning selflearning neuroevolution stochastic neural network topological deep learning modes types network design applications theoretical properties toggle theoretical properties subsection computational power capacity convergence generalization statistics criticism toggle criticism subsection training theory hardware practical counterexamples hybrid approaches dataset bias gallery recent advancements future directions toggle recent advancements future directions subsection image processing speech recognition natural language processing control systems finance medicine content creation see also references bibliography external links toggle table contents neural network machine learning azrbaycanca bnlmgbosanskicataletinadanskdeutscheestiespaolesperantoeuskarafranaisgaeilgegalegohrvatskibahasa indonesiainterlinguaslenskaitalianolatinalatvieulietuviliguremagyarmalagasybahasa melayunederlandsnorsk bokmlnorsk nynorskpolskiportugusromnruna simisimple englishsloveninalnski srpskisuomisvenskatrketing vit english readedit move sidebar hide actions readedit general links hererelated changesupload filepermanent linkpage informationcite pageget shortened urldownload qr code printable version projects wikimedia commonswikibookswikiversitywikidata item move sidebar hide wikipedia free encyclopedia redirected artificial neural network computational model used machine learning based connected hierarchical functions article computational models used artificial intelligence uses see neural network disambiguation part series onmachine learningand data mining paradigms supervised learning unsupervised learning semisupervised learning selfsupervised learning reinforcement learning metalearning online learning batch learning curriculum learning rulebased learning neurosymbolic ai neuromorphic engineering quantum machine learning problems classification generative modeling regression clustering dimensionality reduction density estimation anomaly detection data cleaning automl association rules semantic analysis structured prediction feature engineering feature learning learning rank grammar induction ontology learning multimodal learning supervised learningclassification regression apprenticeship learning decision trees ensembles bagging boosting random forest knn linear regression naive bayes artificial neural networks logistic regression perceptron relevance vector machine rvm support vector machine svm clustering birch cure hierarchical kmeans fuzzy expectationmaximization em dbscan optics mean shift dimensionality reduction factor analysis cca ica lda nmf pca pgd tsne sdl structured prediction graphical models bayes net conditional random field hidden markov anomaly detection ransac knn local outlier factor isolation forest neural networks autoencoder deep learning feedforward neural network recurrent neural network lstm gru esn reservoir computing boltzmann machine restricted gan diffusion model som convolutional neural network unet lenet alexnet deepdream neural radiance field transformer vision mamba spiking neural network memtransistor electrochemical ram ecram reinforcement learning qlearning sarsa temporal difference td multiagent selfplay learning humans active learning crowdsourcing humanintheloop mechanistic interpretability rlhf model diagnostics coefficient determination confusion matrix learning curve roc curve mathematical foundations kernel machines biasvariance tradeoff computational learning theory empirical risk minimization occam learning pac learning statistical learning vc theory topological deep learning journals conferences ecml pkdd neurips icml iclr ijcai ml jmlr related articles glossary artificial intelligence list datasets machinelearning list datasets computer vision image processing outline machine learning vte artificial neural network interconnected group nodes inspired simplification neurons brain circular node represents artificial neuron arrow represents connection output one artificial neuron input another machine learning neural network also artificial neural network neural net abbreviated ann nn computational model inspired structure functions biological neural networks neural network consists connected units nodes called artificial neurons loosely model neurons brain artificial neuron models mimic biological neurons closely also recently investigated shown significantly improve performance connected edges model synapses brain artificial neuron receives signals connected neurons processes sends signal connected neurons signal real number output neuron computed nonlinear function sum inputs called activation function strength signal connection determined weight adjusts learning process typically neurons aggregated layers different layers may perform different transformations inputs signals travel first layer input layer last layer output layer possibly passing multiple intermediate layers hidden layers network typically called deep neural network least two hidden layers artificial neural networks used various tasks including predictive modeling adaptive control solving problems artificial intelligence learn experience derive conclusions complex seemingly unrelated set information training neural networks typically trained empirical risk minimization method based idea optimizing networks parameters minimize difference empirical risk predicted output actual target values given dataset gradientbased methods backpropagation usually used estimate parameters network training phase anns learn labeled training data iteratively updating parameters minimize defined loss function method allows network generalize unseen datasimplified example training neural network object detection network trained multiple images known depict starfish sea urchins correlated nodes represent visual features starfish match ringed texture star outline whereas sea urchins match striped texture oval shape however instance ring textured sea urchin creates weakly weighted association themsubsequent run network input image left network correctly detects starfish however weakly weighted association ringed texture sea urchin also confers weak signal latter one two intermediate nodes addition shell included training gives weak signal oval shape also resulting weak signal sea urchin output weak signals may result false positive result sea urchinin reality textures outlines would represented single nodes rather associated weight patterns multiple nodes history main article history artificial neural networks early work todays deep neural networks based early work statistics years ago simplest kind feedforward neural network fnn linear network consists single layer output nodes linear activation functions inputs fed directly outputs via series weights sum products weights inputs calculated node mean squared errors calculated outputs given target values minimized creating adjustment weights technique known two centuries method least squares linear regression used means finding good rough linear fit set points legendre gauss prediction planetary movement historically digital computers von neumann model operate via execution explicit instructions access memory number processors neural networks hand originated efforts model information processing biological systems framework connectionism unlike von neumann model connectionist computing separate memory processing warren mcculloch walter pitts considered nonlearning computational model neural networks model paved way split two approaches one approach focused biological processes focused application neural networks artificial intelligence late hebb proposed learning hypothesis based mechanism neural plasticity became known hebbian learning used many early neural networks rosenblatts perceptron hopfield network farley clark used computational machines simulate hebbian network neural network computational machines created rochester holland habit duda psychologist frank rosenblatt described perceptron one first implemented artificial neural networks funded united states office naval r joseph mentions even earlier perceptronlike device farley clark farley clark mit lincoln laboratory actually preceded rosenblatt development perceptronlike device however dropped subject perceptron raised public excitement artificial neural networks causing us government drastically increase funding contributed golden age ai fueled optimistic claims made computer scientists regarding ability perceptrons emulate human intelligence first perceptrons adaptive hidden units however joseph also discussed multilayer perceptrons adaptive hidden layer rosenblatt section cited adopted ideas also crediting work h block b w knight unfortunately early efforts lead working learning algorithm hidden units ie deep learning deep learning breakthroughs fundamental conducted anns first working deep learning algorithm group method data handling method train arbitrarily deep neural networks published alexey ivakhnenko lapa soviet union regarded form polynomial regression generalization rosenblatts perceptron paper described deep network eight layers trained method based layer layer training regression analysis superfluous hidden units pruned using separate validation set since activation functions nodes kolmogorovgabor polynomials also first deep networks multiplicative units gates first deep learning multilayer perceptron trained stochastic gradient descent published shunichi amari computer experiments conducted amaris student saito five layer mlp two modifiable layers learned internal representations classify nonlinearily separable pattern classes subsequent developments hardware hyperparameter tunings made endtoend stochastic gradient descent currently dominant training technique kunihiko fukushima introduced relu rectified linear unit activation function rectifier become popular activation function deep learning nevertheless stagnated united states following work minsky papert emphasized basic perceptrons incapable processing exclusiveor circuit insight irrelevant deep networks ivakhnenko amari transfer learning introduced neural networks learning deep learning architectures convolutional neural networks cnns convolutional layers downsampling layers weight replication began neocognitron introduced kunihiko fukushima though trained backpropagation backpropagation backpropagation efficient application chain rule derived gottfried wilhelm leibniz networks differentiable nodes terminology backpropagating errors actually introduced rosenblatt know implement although henry j kelley continuous precursor backpropagation context control theory seppo linnainmaa published modern form backpropagation masters thesis gm ostrovski et al republished paul werbos applied backpropagation neural networks phd thesis reprinted book yet describe algorithm david e rumelhart et al popularised backpropagation cite original work convolutional neural networks kunihiko fukushimas convolutional neural network cnn architecture also introduced max pooling popular downsampling procedure cnns cnns become essential tool computer vision time delay neural network tdnn introduced alex waibel apply cnn phoneme recognition used convolutions weight sharing backpropagation wei zhang applied backpropagationtrained cnn alphabet recognition yann lecun et al created cnn called lenet recognizing handwritten zip codes mail training required days wei zhang implemented cnn optical computing hardware cnn applied medical image object segmentation breast cancer detection mammograms lenet level cnn yann lecun et al classifies digits applied several banks recognize handwritten numbers checks digitized pixel images onward use neural networks transformed field protein structure prediction particular first cascading networks trained profiles matrices produced multiple sequence alignments recurrent neural networks one origin rnn statistical mechanics shunichi amari proposed modify weights ising model hebbian learning rule model associative memory adding component learning popularized hopfield network john hopfield another origin rnn neuroscience word recurrent used describe looplike structures anatomy cajal observed recurrent semicircles cerebellar cortex hebb considered reverberating circuit explanation shortterm memory mcculloch pitts paper considered neural networks contain cycles noted current activity networks affected activity indefinitely far past recurrent neural network array architecture rather multilayer perceptron architecture namely crossbar adaptive array used direct recurrent connections output supervisor teaching inputs addition computing actions decisions computed internal state evaluations emotions consequence situations eliminating external supervisor introduced selflearning method neural networks cognitive psychology journal american psychologist early carried debate relation cognition emotion zajonc stated emotion computed first independent cognition lazarus stated cognition computed first inseparable emotion crossbar adaptive array gave neural network model cognitionemotion relation example debate ai system recurrent neural network contributed issue time addressed cognitive psychology two early influential works jordan network elman network applied rnn study cognitive psychology backpropagation work well deep rnns overcome problem jrgen schmidhuber proposed neural sequence chunker neural history compressor introduced important concepts selfsupervised pretraining p chatgpt neural knowledge distillation neural history compressor system solved deep learning task required subsequent layers rnn unfolded time sepp hochreiters diploma thesis identified analyzed vanishing gradient problem proposed recurrent residual connections solve schmidhuber introduced long shortterm memory lstm set accuracy records multiple applications domains yet modern version lstm required forget gate introduced became default choice rnn architecture inspired statistical mechanics several architectures methods developed terry sejnowski peter dayan geoffrey hinton etc including boltzmann machine restricted boltzmann machine helmholtz machine wakesleep algorithm designed unsupervised learning deep generative models deep learning anns began winning prizes image recognition contests approaching human level performance various tasks initially pattern recognition handwriting recognition cnn named dannet dan ciresan ueli meier jonathan masci luca maria gambardella jrgen schmidhuber achieved first time superhuman performance visual pattern recognition contest outperforming traditional methods factor contests also showed maxpooling cnns gpu improved performance significantly october alexnet alex krizhevsky ilya sutskever geoffrey hinton largescale imagenet competition significant margin shallow machine learning methods incremental improvements included vgg network karen simonyan andrew zisserman googles inceptionv ng dean created network learned recognize higherlevel concepts cats watching unlabeled images unsupervised pretraining increased computing power gpus distributed computing allowed use larger networks particularly image visual recognition problems became known deep learning radial basis function wavelet networks introduced shown offer best approximation properties applied nonlinear system identification classification applications generative adversarial network gan ian goodfellow et al became state art generative modeling period gan principle originally published jrgen schmidhuber called artificial curiosity two neural networks contest form zerosum game one networks gain networks loss first network generative model models probability distribution output patterns second network learns gradient descent predict reactions environment patterns excellent image quality achieved nvidias stylegan based progressive gan tero karras et al gan generator grown small large scale pyramidal fashion image generation gan reached popular success provoked discussions concerning deepfakes diffusion models eclipsed gans generative modeling since systems dalle stable diffusion state art training deep neural network layers stacking many layers led steep reduction training accuracy known degradation problem two techniques developed train deep networks highway network published may residual neural network resnet december resnet behaves like opengated highway net main article transformer deep learning architecture history seqseq model developed attention mechanisms added led modern transformer architecture attention need requires computation time quadratic size context window jrgen schmidhubers fast weight controller scales linearly later shown equivalent unnormalized linear transformer transformers increasingly become model choice natural language processing many modern large language models chatgpt gpt bert use architecture models section may confusing unclear readers please help clarify section might discussion talk page april learn remove messagefurther information mathematics artificial neural networksneuron myelinated axon signal flow inputs dendrites outputs axon terminals anns began attempt exploit architecture human brain perform tasks conventional algorithms little success soon reoriented towards improving empirical results abandoning attempts remain true biological precursors anns ability learn model nonlinearities complex relationships achieved neurons connected various patterns allowing output neurons become input others network forms directed weighted graph artificial neural network consists simulated neurons neuron connected nodes via links like biological axonsynapsedendrite connection nodes connected links take data use perform specific operations tasks data link weight determining strength one nodes influence another allowing weights choose signal neurons artificial neurons main article artificial neuron anns composed artificial neurons conceptually derived biological neurons artificial neuron inputs produces single output sent multiple neurons inputs feature values sample external data images documents outputs neurons outputs final output neurons neural net accomplish task recognizing object image find output neuron take weighted sum inputs weighted weights connections inputs neuron add bias term sum weighted sum sometimes called activation weighted sum passed usually nonlinear activation function produce output initial inputs external data images documents ultimate outputs accomplish task recognizing object image organization neurons typically organized multiple layers especially deep learning neurons one layer connect neurons immediately preceding immediately following layers layer receives external data input layer layer produces ultimate result output layer zero hidden layers single layer unlayered networks also used two layers multiple connection patterns possible fully connected every neuron one layer connecting every neuron next layer pooling group neurons one layer connects single neuron next layer thereby reducing number neurons layer neurons connections form directed acyclic graph known feedforward networks alternatively networks allow connections neurons previous layers known recurrent networks hyperparameter main article hyperparameter machine learning hyperparameter constant parameter whose value set learning process begins values parameters derived via learning examples hyperparameters include learning rate number hidden layers batch size values hyperparameters dependent hyperparameters example size layers depend overall number layers learning section includes list references related reading external links sources remain unclear lacks inline citations please help improve section introducing precise citations august learn remove messagesee also mathematical optimization estimation theory machine learning learning adaptation network better handle task considering sample observations learning involves adjusting weights optional thresholds network improve accuracy result done minimizing observed errors learning complete examining additional observations usefully reduce error rate even learning error rate typically reach learning error rate high network typically must redesigned practically done defining cost function evaluated periodically learning long output continues decline learning continues cost frequently defined statistic whose value approximated outputs actually numbers error low difference output almost certainly cat correct answer cat small learning attempts reduce total differences across observations learning models viewed straightforward application optimization theory statistical estimation learning rate main article learning rate learning rate defines size corrective steps model takes adjust errors observation high learning rate shortens training time lower ultimate accuracy lower learning rate takes longer potential greater accuracy optimizations quickprop primarily aimed speeding error minimization improvements mainly try increase reliability order avoid oscillation inside network alternating connection weights improve rate convergence refinements use adaptive learning rate increases decreases appropriate concept momentum allows balance gradient previous change weighted weight adjustment depends degree previous change momentum close emphasizes gradient value close emphasizes last change cost function possible define cost function ad hoc frequently choice determined functions desirable properties convexity arises model eg probabilistic model models posterior probability used inverse cost backpropagation main article backpropagation backpropagation method used adjust connection weights compensate error found learning error amount effectively divided among connections technically backpropagation calculates gradient derivative cost function associated given state respect weights weight updates done via stochastic gradient descent methods extreme learning machines noprop networks training without backtracking weightless networks nonconnectionist neural networks learning paradigms section includes list references related reading external links sources remain unclear lacks inline citations please help improve section introducing precise citations august learn remove message machine learning commonly separated three main learning paradigms supervised learning unsupervised learning reinforcement learning corresponds particular learning task supervised learning supervised learning uses set paired inputs desired outputs learning task produce desired output input case cost function related eliminating incorrect deductions commonly used cost meansquared error tries minimize average squared error networks output desired output tasks suited supervised learning pattern recognition also known classification regression also known function approximation supervised learning also applicable sequential data eg handwriting speech gesture recognition thought learning teacher form function provides continuous feedback quality solutions obtained thus far unsupervised learning unsupervised learning input data given along cost function function data x displaystyle textstyle x networks output cost function dependent task model domain priori assumptions implicit properties model parameters observed variables trivial example consider model f x displaystyle textstyle fxa displaystyle textstyle constant cost c e x f x displaystyle textstyle cexfx minimizing cost produces value displaystyle textstyle equal mean data cost function much complicated form depends application example compression could related mutual information x displaystyle textstyle x f x displaystyle textstyle fx whereas statistical modeling could related posterior probability model given data note examples quantities would maximized rather minimized tasks fall within paradigm unsupervised learning general estimation problems applications include clustering estimation statistical distributions compression filtering reinforcement learning main article reinforcement learning see also stochastic control applications playing video games actor takes string actions receiving generally unpredictable response environment one goal win game ie generate positive lowest cost responses reinforcement learning aim weight network devise policy perform actions minimize longterm expected cumulative cost point time agent performs action environment generates observation instantaneous cost according usually unknown rules rules longterm cost usually estimated juncture agent decides whether explore new actions uncover costs exploit prior learning proceed quickly formally environment modeled markov decision process mdp states n displaystyle textstyle ssnin actions displaystyle textstyle aamin state transitions known probability distributions used instead instantaneous cost distribution p c displaystyle textstyle pctst observation distribution p x displaystyle textstyle pxtst transition distribution p displaystyle textstyle pststat policy defined conditional distribution actions given observations taken together two define markov chain mc aim discover lowestcost mc anns serve learning component applications dynamic programming coupled anns giving neurodynamic programming applied problems involved vehicle routing video games natural resource management medicine anns ability mitigate losses accuracy even reducing discretization grid density numerically approximating solution control problems tasks fall within paradigm reinforcement learning control problems games sequential decision making tasks selflearning selflearning neural networks introduced along neural network capable selflearning named crossbar adaptive array caa system one input situation one output action behavior neither external advice input external reinforcement input environment caa computes crossbar fashion decisions actions emotions feelings encountered situations system driven interaction cognition emotion given memory matrix w crossbar selflearning algorithm iteration performs following computation situation perform action receive consequence situation compute emotion consequence situation vs update crossbar memory vs backpropagated value secondary reinforcement emotion toward consequence situation caa exists two environments one behavioral environment behaves genetic environment receives initial emotions encountered situations behavioral environment received genome vector species vector genetic environment caa learn goalseeking behavior behavioral environment contains desirable undesirable situations neuroevolution main article neuroevolution neuroevolution create neural network topologies weights using evolutionary computation competitive sophisticated gradient descent approaches one advantage neuroevolution may less prone get caught dead ends stochastic neural network stochastic neural networks originating sherringtonkirkpatrick models type artificial neural network built introducing random variations network either giving networks artificial neurons stochastic transfer functions giving stochastic weights makes useful optimization problems since random fluctuations help network escape local minima stochastic neural networks trained using bayesian approach known bayesian neural networks topological deep learning topological deep learning first introduced emerging approach machine learning integrates topology deep neural networks address highly intricate highorder data initially rooted algebraic topology tdl since evolved versatile framework incorporating mathematical disciplines differential topology geometric topology successful example mathematical deep learning tdl continues inspire advancements mathematical artificial intelligence fostering mutually beneficial relationship ai mathematics bayesian framework distribution set allowed models chosen minimize cost evolutionary methods gene expression programming simulated annealing expectationmaximization nonparametric methods particle swarm optimization learning algorithms convergent recursion learning algorithm cerebellar model articulation controller cmac neural networks modes section includes list references related reading external links sources remain unclear lacks inline citations please help improve section introducing precise citations august learn remove message two modes learning available stochastic batch stochastic learning input creates weight adjustment batch learning weights adjusted based batch inputs accumulating errors batch stochastic learning introduces noise process using local gradient calculated one data point reduces chance network getting stuck local minima however batch learning typically yields faster stable descent local minimum since update performed direction batchs average error common compromise use minibatches small batches samples batch selected stochastically entire data set types main article types artificial neural networks anns evolved broad family techniques advanced state art across multiple domains simplest types one static components including number units number layers unit weights topology dynamic types allow one evolve via learning latter much complicated shorten learning periods produce better results types allowrequire learning supervised operator others operate independently types operate purely hardware others purely software run general purpose computers main breakthroughs include convolutional neural networks proven particularly successful processing visual twodimensional data long shortterm memory avoids vanishing gradient problem handle signals mix low high frequency components aiding largevocabulary speech recognition texttospeech synthesis photoreal talking heads competitive networks generative adversarial networks multiple networks varying structure compete tasks winning game deceiving opponent authenticity input network design using artificial neural networks requires understanding characteristics choice model depends data representation application model parameters include number type connectedness network layers well size connection type full pooling etc overly complex models learn slowly learning algorithm numerous tradeoffs exist learning algorithms almost algorithm work well correct hyperparameters training particular data set however selecting tuning algorithm training unseen data requires significant experimentation robustness model cost function learning algorithm selected appropriately resulting ann become robust neural architecture nas uses machine learning automate ann design various approaches nas designed networks compare well handdesigned systems basic algorithm propose candidate model evaluate dataset use results feedback teach nas network available systems include automl autokeras scikitlearn library provides functions help building deep network scratch implement deep network tensorflow keras hyperparameters must also defined part design learned governing matters many neurons layer learning rate step stride depth receptive field padding cnns etc python code snippet provides overview training function uses training dataset number hidden layer units learning rate number iterations parametersdef trainx nhidden learningrate niter ninput xshape random initialize weights biases w nprandomrandnninput nhidden b npzeros nhidden w nprandomrandnnhidden b npzeros iteration feed layers latest weights biases rangeniter z npdotx w b sigmoidz z npdota w b z dz dw npdotat dz db npsumdz axis keepdimstrue dz npdotdz wt sigmoidderivativez dw npdotxy dz db npsumdz axis update weights biases gradients w learningrate dw w learningrate dw b learningrate db b learningrate db printepoch loss npmeannpsquaredz model w w b b w w b b return model applications ability reproduce model nonlinear processes artificial neural networks found applications many disciplines include function approximation regression analysis including time series prediction fitness approximation modeling data processing including filtering clustering blind source separation compression nonlinear system identification control including vehicle control trajectory prediction adaptive control process control natural resource management pattern recognition including radar systems face identification signal classification novelty detection reconstruction object recognition sequential decision making sequence recognition including gesture speech handwritten printed text recognition sensor data analysis including image analysis robotics including directing manipulators prostheses data mining including knowledge discovery databases finance exante models specific financial longrun forecasts artificial financial markets quantum chemistry general game playing generative ai data visualization machine translation social network filtering email spam filtering medical diagnosis anns used diagnose several types cancers distinguish highly invasive cancer cell lines less invasive lines using cell shape information anns used accelerate reliability analysis infrastructures subject natural disasters predict foundation settlements also useful mitigate flood use anns modelling rainfallrunoff anns also used building blackbox models geoscience hydrology ocean modelling coastal engineering geomorphology anns employed cybersecurity objective discriminate legitimate activities malicious ones example machine learning used classifying android malware identifying domains belonging threat actors detecting urls posing security risk underway ann systems designed penetration testing detecting botnets credit cards frauds network intrusions anns proposed tool solve partial differential equations physics simulate properties manybody open quantum systems brain anns studied shortterm behavior individual neurons dynamics neural circuitry arise interactions individual neurons behavior arise abstract neural modules represent complete subsystems studies considered longand shortterm plasticity neural systems relation learning memory individual neuron system level possible create profile users interests pictures using artificial neural networks trained object recognition beyond traditional applications artificial neural networks increasingly utilized interdisciplinary materials science instance graph neural networks gnns demonstrated capability scaling deep learning discovery new stable materials efficiently predicting total energy crystals application underscores adaptability potential anns tackling complex problems beyond realms predictive modeling artificial intelligence opening new pathways scientific discovery innovation theoretical properties computational power multilayer perceptron universal function approximator proven universal approximation theorem however proof constructive regarding number neurons required network topology weights learning parameters specific recurrent architecture rationalvalued weights opposed full precision real numbervalued weights power universal turing machine using finite number neurons standard linear connections use irrational values weights results machine superturing powerfailed verification capacity models capacity property corresponds ability model given function related amount information stored network notion complexity two notions capacity known community information capacity vc dimension information capacity perceptron intensively discussed sir david mackays book summarizes work thomas cover capacity network standard neurons convolutional derived four rules derive understanding neuron electrical element information capacity captures functions modelable network given data input second notion vc dimension vc dimension uses principles measure theory finds maximum capacity best possible circumstances given input data specific form noted vc dimension arbitrary inputs half information capacity perceptron vc dimension arbitrary points sometimes referred memory capacity convergence models may consistently converge single solution firstly local minima may exist depending cost function model secondly optimization method used might guarantee converge begins far local minimum thirdly sufficiently large data parameters methods become impractical another issue worthy mention training may cross saddle point may lead convergence wrong direction convergence behavior certain types ann architectures understood others width network approaches infinity ann well described first order taylor expansion throughout training inherits convergence behavior affine models another example parameters small observed anns often fit target functions low high frequencies behavior referred spectral bias frequency principle neural networks phenomenon opposite behavior well studied iterative numerical schemes jacobi method deeper neural networks observed biased towards low frequency functions generalization statistics section includes list references related reading external links sources remain unclear lacks inline citations please help improve section introducing precise citations august learn remove message applications whose goal create system generalizes well unseen examples face possibility overtraining arises convoluted overspecified systems network capacity significantly exceeds needed free parameters two approaches address overtraining first use crossvalidation similar techniques check presence overtraining select hyperparameters minimize generalization error second use form regularization concept emerges probabilistic bayesian framework regularization performed selecting larger prior probability simpler models also statistical learning theory goal minimize two quantities empirical risk structural risk roughly corresponds error training set predicted error unseen data due overfitting confidence analysis neural network supervised neural networks use mean squared error mse cost function use formal statistical methods determine confidence trained model mse validation set used estimate variance value used calculate confidence interval network output assuming normal distribution confidence analysis made way statistically valid long output probability distribution stays network modified assigning softmax activation function generalization logistic function output layer neural network softmax component componentbased network categorical target variables outputs interpreted posterior probabilities useful classification gives certainty measure classifications softmax activation function e x j c e x j displaystyle yifrac exisum jcexj criticism training common criticism neural networks particularly robotics require many training samples realworld operation learning machine needs sufficient representative examples order capture underlying structure allows generalize new cases potential solutions include randomly shuffling training examples using numerical optimization algorithm take large steps changing network connections following example grouping examples socalled minibatches andor introducing recursive least squares algorithm cmac dean pomerleau uses neural network train robotic vehicle drive multiple types roads single lane multilane dirt etc large amount devoted extrapolating multiple training scenarios single training experience preserving past training diversity system become overtrained example presented series right turnsit learn always turn right theory central claim anns embody new powerful general principles processing information principles illdefined often claimedby emergent network allows simple statistical association basic function artificial neural networks described learning recognition alexander dewdney former scientific american columnist commented result artificial neural networks somethingfornothing quality one imparts peculiar aura laziness distinct lack curiosity good computing systems human hand mind intervenes solutions found magic one seems learned anything one response dewdney neural networks successfully used handle many complex diverse tasks ranging autonomously flying aircraft detecting credit card fraud mastering game go technology writer roger bridgman commented neural networks instance dock hyped high heaven hasnt also could create successful net without understanding worked bunch numbers captures behaviour would probability opaque unreadable tablevalueless scientific resource spite emphatic declaration science technology dewdney seems pillory neural nets bad science devising trying good engineers unreadable table useful machine could read would still well worth although true analyzing learned artificial neural network difficult much easier analyze learned biological neural network moreover recent emphasis explainability ai contributed towards development methods notably based attention mechanisms visualizing explaining learned neural networks furthermore reers involved exploring learning algorithms neural networks gradually uncovering generic principles allow learning machine successful example bengio lecun wrote article regarding local vs nonlocal learning well shallow vs deep architecture biological brains use shallow deep circuits reported brain anatomy displaying wide variety invariance weng argued brain selfwires largely according signal statistics therefore serial cascade catch major statistical dependencies hardware large effective neural networks require considerable computing resources brain hardware tailored task processing signals graph neurons simulating even simplified neuron von neumann architecture may consume vast amounts memory storage furthermore designer often needs transmit signals many connections associated neurons require enormous cpu power time argue resurgence neural networks twentyfirst century largely attributable advances hardware computing power especially delivered gpgpus gpus increased around millionfold making standard backpropagation algorithm feasible training networks several layers deeper use accelerators fpgas gpus reduce training times months days neuromorphic engineering physical neural network addresses hardware difficulty directly constructing nonvonneumann chips directly implement neural networks circuitry another type chip optimized neural network processing called tensor processing unit tpu practical counterexamples analyzing learned ann much easier analyzing learned biological neural network furthermore reers involved exploring learning algorithms neural networks gradually uncovering general principles allow learning machine successful example local vs nonlocal learning shallow vs deep architecture hybrid approaches advocates hybrid models combining neural networks symbolic approaches say mixture better capture mechanisms human mind dataset bias neural networks dependent quality data trained thus low quality data imbalanced representativeness lead model learning perpetuating societal biases inherited biases become especially critical anns integrated realworld scenarios training data may imbalanced due scarcity data specific race gender attribute imbalance result model inadequate representation understanding underrepresented groups leading discriminatory outcomes exacerbate societal inequalities especially applications like facial recognition hiring processes law enforcement example amazon scrap recruiting tool model favored men women jobs software engineering due higher number male workers field program would penalize resume word woman name womens college however use synthetic data help reduce dataset bias increase representation datasets gallery singlelayer feedforward artificial neural network arrows originating x displaystyle scriptstyle x omitted clarity p inputs network q outputs system value qth output q displaystyle yq calculated q k x w q b q displaystyle scriptstyle yqksum ixiwiqbq twolayer feedforward artificial neural network artificial neural network ann dependency graph singlelayer feedforward artificial neural network inputs hidden nodes outputs given position state direction outputs wheel based control values twolayer feedforward artificial neural network inputs x hidden nodes outputs given position state direction environment values outputs thruster based control values parallel pipeline structure cmac neural network learning algorithm converge one step recent advancements future directions artificial neural networks anns undergone significant advancements particularly ability model complex systems handle large data sets adapt various types applications evolution past decades marked broad range applications fields image processing speech recognition natural language processing finance medicine image processing realm image processing anns employed tasks image classification object recognition image segmentation instance deep convolutional neural networks cnns important handwritten digit recognition achieving stateoftheart performance demonstrates ability anns effectively process interpret complex visual information leading advancements fields ranging automated surveillance medical imaging speech recognition modeling speech signals anns used tasks like speaker identification speechtotext conversion deep neural network architectures introduced significant improvements large vocabulary continuous speech recognition outperforming traditional techniques advancements enabled development accurate efficient voiceactivated systems enhancing user interfaces technology products natural language processing natural language processing anns used tasks text classification sentiment analysis machine translation enabled development models accurately translate languages understand context sentiment textual data categorize text based content implications automated customer service content moderation language understanding technologies control systems domain control systems anns used model dynamic systems tasks system identification control design optimization instance deep feedforward neural networks important system identification control applications finance information applications artificial intelligence trading investment anns used stock market prediction credit scoring investing anns process vast amounts financial data recognize complex patterns forecast stock market trends aiding investors risk managers making informed decisions credit scoring anns offer datadriven personalized assessments creditworthiness improving accuracy default predictions automating lending process anns require highquality data careful tuning blackbox nature pose challenges interpretation nevertheless ongoing advancements suggest anns continue play role finance offering valuable insights enhancing risk management strategies medicine anns able process analyze vast medical datasets enhance diagnostic accuracy especially interpreting complex medical imaging early disease detection predicting patient outcomes personalized treatment planning drug discovery anns speed identification potential drug candidates predict efficacy safety significantly reducing development time costs additionally application personalized medicine healthcare data analysis allows tailored therapies efficient patient care management ongoing aimed addressing remaining challenges data privacy model interpretability well expanding scope ann applications medicine content creation anns generative adversarial networks gan transformers used content creation across numerous industries deep learning models able learn style artist musician huge datasets generate completely new artworks music compositions instance dalle deep neural network trained million pairs images texts across internet create artworks based text entered user field music transformers used create original music commercials documentaries companies aiva jukedeck marketing industry generative models used create personalized advertisements consumers additionally major film companies partnering technology companies analyze financial success film partnership warner bros technology company cinelytic established furthermore neural networks found uses video game creation non player characters npcs make decisions based characters currently game see also adaline autoencoder bioinspired computing blue brain project catastrophic interference cognitive architecture connectionist expert system connectomics deep image prior digital morphogenesis efficiently updatable neural network evolutionary algorithm family curves genetic algorithm hyperdimensional computing situ adaptive tabulation large width limits neural networks list machine learning concepts memristor neural gas neural network software optical neural network parallel distributed processing philosophy artificial intelligence predictive analytics quantum neural network support vector machine spiking neural network stochastic parrot tensor product network topological deep learning references hardesty l april explained neural networks mit news office archived original march retrieved june yang z yang z comprehensive biomedical physics karolinska institute stockholm sweden elsevier p isbn archived original july retrieved july bishop cm august pattern recognition machine learning new york springer isbn b vapnik vn vapnik vn nature statistical learning theory corrected nd print ed new york berlin heidelberg springer isbn b ian goodfellow yoshua bengio aaron courville deep learning mit press archived original april retrieved june ferrie c kaiser neural networks babies sourcebooks isbn mansfield merriman list writings relating method least squares stigler sm gauss invention least squares ann stat doiaos bretscher linear algebra applications rd ed upper saddle river nj prentice hall b c e f g h schmidhuber j annotated history modern ai deep learning arxiv csne stigler sm history statistics measurement uncertainty cambridge harvard isbn b mcculloch ws pitts w december logical calculus ideas immanent nervous activity bulletin mathematical biophysics doibf issn archived original october retrieved august kleene representation events nerve nets finite automata annals mathematics studies princeton university press pp archived original may retrieved june hebb organization behavior new york wiley isbn cite book isbn date incompatibility help farley b wa clark simulation selforganizing systems digital computer ire transactions information theory doitit rochester n jh holland lh habit wl duda tests cell assembly theory action brain using large digital computer ire transactions information theory doitit haykin neural networks learning machines rd edition rosenblatt f perceptron probabilistic model information storage organization brain psychological review citeseerx doih pmid scid werbos p beyond regression new prediction analysis behavioral sciences rosenblatt f perceptrona perceiving recognizing automaton report cornell aeronautical laboratory olazaran sociological study official history perceptrons controversy social studies science doi jstor scid b joseph rd contributions perceptron theory cornell aeronautical laboratory report vg g buffalo russel stuart norvig peter artificial intelligence modern approach pdf rd ed united states america pearson education pp isbn b rosenblatt f principles neurodynamics spartan new york ivakhnenko ag lapa vg cybernetics forecasting techniques american elsevier publishing co isbn ivakhnenko march heuristic selforganization problems engineering cybernetics automatica doi archived original august retrieved august ivakhnenko polynomial theory complex systems pdf ieee transactions systems man cybernetics smc doitsmc archived pdf original august retrieved november robbins h monro stochastic approximation method annals mathematical statistics doiaoms amari theory adaptive pattern classifier ieee transactions ec fukushima k visual feature extraction multilayered network analog threshold elements ieee transactions systems science cybernetics doitssc sonoda murata n neural network unbounded activation functions universal approximator applied computational harmonic analysis arxiv doijacha scid ramachandran p barret z quoc vl october ing activation functions arxiv csne minsky papert perceptrons introduction computational geometry mit press isbn bozinovski fulgosi influence pattern similarity transfer learning base perceptron training original croatian proceedings symposium informatica bled bozinovski reminder first paper transfer learning neural networks informatica b fukushima k neural network model mechanism pattern recognition unaffected shift positionneocognitron trans iece japanese ja doibf pmid scid fukushima k neocognitron selforganizing neural network model mechanism pattern recognition unaffected shift position biol cybern doibf pmid scid b c schmidhuber j deep learning neural networks overview neural networks arxiv doijneunet pmid scid leibniz gw early mathematical manuscripts leibniz translated latin texts published carl immanuel gerhardt critical historical notes leibniz published chain rule memoir open court publishing company isbn cite book isbn date incompatibility help kelley hj gradient theory optimal flight paths ars journal doi linnainmaa representation cumulative rounding error algorithm taylor expansion local rounding errors masters finnish university helsinki p linnainmaa taylor expansion accumulated rounding error bit numerical mathematics doibf scid ostrovski gm volinym boris ww computation derivatives wiss z tech hochschule chemistry b schmidhuber j october invented backpropagation idsia switzerland archived original july retrieved september werbos p applications advances nonlinear sensitivity analysis pdf system modeling optimization springer pp archived pdf original april retrieved july anderson ja rosenfeld e eds talking nets oral history neural networks mit press doimitpress isbn archived original october retrieved august werbos pj roots backpropagation ordered derivatives neural networks political forecasting new york john wiley sons isbn rumelhart de hinton ge williams rj october learning representations backpropagating errors nature bibcodenaturr doia issn archived original march retrieved march fukushima k miyake january neocognitron new algorithm pattern recognition tolerant deformations shifts position pattern recognition bibcodepatref doi issn archived original october retrieved september waibel december phoneme recognition using timedelay neural networks pdf meeting institute electrical information communication engineers ieice tokyo japan archived pdf original september retrieved september alexander waibel et al phoneme recognition using timedelay neural networks archived december wayback machine ieee transactions acoustics speech signal processing volume pp march zhang w shiftinvariant pattern recognition neural network optical architecture proceedings annual conference japan society applied physics archived original june retrieved april lecun et al backpropagation applied handwritten zip code recognition neural computation pp zhang w parallel distributed processing model local spaceinvariant interconnections optical architecture applied optics bibcodeapoptz doiao pmid archived original february retrieved april zhang w image processing human corneal endothelium based learning network applied optics bibcodeapoptz doiao pmid archived original june retrieved september zhang w computerized detection clustered microcalcifications digital mammograms using shiftinvariant artificial neural network medical physics bibcodemedphz doi pmid archived original june retrieved september lecun lon bottou yoshua bengio patrick haffner gradientbased learning applied document recognition pdf proceedings ieee citeseerx doi scid archived original pdf october retrieved october qian ning terrence j sejnowski predicting secondary structure globular proteins using neural network models journal molecular biology bohr henrik jakob bohr sren brunak rodney mj cotterill benny lautrup leif nrskov ole h olsen steffen b petersen protein secondary structure homology neural networks helices rhodopsin febs letters rost burkhard chris sander prediction protein secondary structure better accuracy journal molecular biology amari si november learning patterns pattern sequences selforganizing nets threshold elements ieee transactions computers c doitc issn archived original october retrieved august hopfield jj neural networks physical systems emergent collective computational abilities proceedings national academy sciences bibcodepnash doipnas pmc pmid espinosasanchez jm gomezmarin de castro f july importance cajals lorente de ns neuroscience birth cybernetics neuroscientist doi hdl issn pmid archived original october retrieved august reverberating circuit oxford reference archived original october retrieved july b bozinovski selflearning system using secondary reinforcement trappl robert ed cybernetics systems proceedings sixth european meeting cybernetics systems northholland pp isbn bozinovski neuro genetic agents structural theory selfreinforcement learning systems cmpsci technical report university massachusetts amherst archived october wayback machine r zajonc feeling thinking preferences need inferences american psychologist lazarus r thoughts relations emotion cognition american psychologist bozinovski modeling mechanisms cognitionemotion interaction artificial neural networks since procedia computer science p httpscoreacukdownloadpdfpdf archived march wayback machine schmidhuber j april neural sequence chunkers pdf tr fki tu munich archived pdf original september retrieved september schmidhuber j learning complex extended sequences using principle history compression based tr fki pdf neural computation doineco scid archived pdf original september retrieved september schmidhuber j habilitation thesis system modeling optimization pdf archived pdf original august retrieved september page ff demonstrates credit assignment across equivalent layers unfolded rnn b hochreiter untersuchungen zu dynamischen neuronalen netzen archived march wayback machine diploma thesis institut f informatik technische univ munich advisor j schmidhuber hochreiter et al january gradient flow recurrent nets difficulty learning longterm dependencies kolen jf kremer sc eds field guide dynamical recurrent networks john wiley sons isbn archived original may retrieved june sepp hochreiter jrgen schmidhuber august long short term memory wikidata q hochreiter schmidhuber j november long shortterm memory neural computation doineco pmid scid gers f schmidhuber j cummins f learning forget continual prediction lstm th international conference artificial neural networks icann vol pp doicp isbn ackley dh hinton ge sejnowski tj january learning algorithm boltzmann machines cognitive science dois issn archived original september retrieved august smolensky p chapter information processing dynamical systems foundations harmony theory pdf rumelhart de mclelland jl eds parallel distributed processing explorations microstructure cognition volume foundations mit press pp isbn x archived pdf original july retrieved august peter hinton ge neal rm zemel rs helmholtz machine neural computation doineco hdldde pmid scid hinton ge dayan p frey bj neal r may wakesleep algorithm unsupervised neural networks science bibcodescih doiscience pmid scid kurzweil ai interview archived august wayback machine juergen schmidhuber eight competitions deep learning team bioinspired deep learning keeps winning competitions kurzweilai kurzweilainet archived original august retrieved june cirean dc meier u gambardella lm schmidhuber j september deep big simple neural nets handwritten digit recognition neural computation arxiv doinecoa issn pmid scid ciresan dc meier u masci j gambardella l schmidhuber j flexible high performance convolutional neural networks image classification pdf international joint conference artificial intelligence doiijcai archived pdf original september retrieved june ciresan giusti gambardella lm schmidhuber j pereira f burges cj bottou l weinberger kq eds advances neural information processing systems pdf curran associates inc pp archived pdf original august retrieved june ciresan giusti gambardella l schmidhuber j mitosis detection breast cancer histology images deep neural networks medical image computing computerassisted intervention miccai lecture notes computer science vol pp doi isbn pmid ciresan meier u schmidhuber j multicolumn deep neural networks image classification ieee conference computer vision pattern recognition pp arxiv doicvpr isbn scid krizhevsky sutskever hinton g imagenet classification deep convolutional neural networks pdf nips neural information processing systems lake tahoe nevada archived pdf original january retrieved may simonyan k andrew z deep convolution networks large scale image recognition arxiv cscv szegedy c going deeper convolutions pdf cvpr arxiv archived pdf original september retrieved august ng dean j building highlevel features using large scale unsupervised learning arxiv cslg b billings sa nonlinear system identification narmax methods time frequency spatiotemporal domains wiley isbn b goodfellow pougetabadie j mirza xu b wardefarley ozair et al generative adversarial networks pdf proceedings international conference neural information processing systems nips pp archived pdf original november retrieved august schmidhuber j possibility implementing curiosity boredom modelbuilding neural controllers proc sab mit pressbradford books pp schmidhuber j generative adversarial networks special cases artificial curiosity also closely related predictability minimization neural networks arxiv doijneunet pmid scid gan nvidias hyperrealistic face generator syncedreviewcom december archived original september retrieved october karras aila laine lehtinen j february progressive growing gans improved quality stability variation arxiv csne prepare dont panic synthetic media deepfakes witnessorg archived original december retrieved november sohldickstein j weiss e maheswaranathan n ganguli june deep unsupervised learning using nonequilibrium thermodynamics pdf proceedings nd international conference machine learning pmlr arxiv archived pdf original september retrieved august simonyan k zisserman april deep convolutional networks largescale image recognition arxiv k zhang x ren sun j delving deep rectifiers surpassing humanlevel performance imagenet classification arxiv cscv k zhang x ren sun j december deep residual learning image recognition arxiv srivastava rk greff k schmidhuber j may highway networks arxiv cslg k zhang x ren sun j deep residual learning image recognition ieee conference computer vision pattern recognition cvpr ieee pp arxiv doicvpr isbn archived original october retrieved april linn december microsoft reers win imagenet computer vision challenge ai blog archived original may retrieved june vaswani shazeer n parmar n uszkoreit j jones l gomez et al june attention need arxiv cscl schmidhuber j learning control fastweight memories alternative recurrent nets pdf neural computation doineco scid katharopoulos vyas pappas n fleuret f transformers rnns fast autoregressive transformers linear attention icml pmlr pp archived original july retrieved september schlag irie k schmidhuber j linear transformers secretly fast weight programmers icml springer pp wolf debut l sanh v chaumond j delangue c moi et al transformers stateoftheart natural language processing proceedings conference empirical methods natural language processing system demonstrations pp doivemnlpdemos scid b zell chapter simulation neuronaler netze simulation neural networks german st ed addisonwesley isbn oclc artificial intelligence rd ed addisonwesley pub co isbn abbod mf application artificial intelligence management urological cancer journal urology doijjuro pmid dawson cw artificial neural network approach rainfallrunoff modelling hydrological sciences journal bibcodehydsjd doi machine learning dictionary cseunsweduau archived original august retrieved november ciresan ueli meier jonathan masci luca gambardella jurgen schmidhuber flexible high performance convolutional neural networks image classification pdf proceedings twentysecond international joint conference artificial intelligencevolume volume two archived pdf original april retrieved july zell simulation neuronaler netze simulation neural networks german st ed addisonwesley p isbn miljanovic februarymarch comparative analysis recurrent finite impulse response neural networks time series prediction pdf indian journal computer engineering archived pdf original may retrieved august kelleher jd mac namee b darcy fundamentals machine learning predictive data analytics algorithms worked examples case studies nd ed cambridge mit press isbn oclc wei j april forget learning rate decay loss arxiv cslg li fu li h zhang sw june improved training algorithm back propagation neural network selfadaptive learning rate international conference computational intelligence natural computing vol pp doicinc isbn scid huang gb zhu qy siew ck extreme learning machine theory applications neurocomputing citeseerx doijneucom scid widrow b et al noprop algorithm new learning algorithm multilayer neural networks neural networks doijneunet pmid ollivier charpiat g training recurrent networks without backtracking arxiv csne hinton ge practical guide training restricted boltzmann machines tech rep utml tr archived original may retrieved june esann full citation needed bernard e introduction machine learning champaign wolfram media p isbn archived original may retrieved march bernard e introduction machine learning champaign wolfram media p isbn archived original may retrieved march bernard e introduction machine learning wolfram media inc p isbn archived original may retrieved july ojha vk abraham snel v april metaheuristic design feedforward neural networks review two decades engineering applications artificial intelligence arxiv bibcodearxivo doijengappai scid dominic das r whitley anderson c july genetic reinforcement learning neural networks ijcnnseattle international joint conference neural networks ijcnnseattle international joint conference neural networks seattle washington us ieee pp doiijcnn isbn hoskins j himmelblau dm process control via artificial neural networks reinforcement learning computers chemical engineering doib bertsekas tsitsiklis j neurodynamic programming athena scientific p isbn archived original june retrieved june secomandi n comparing neurodynamic programming algorithms vehicle routing problem stochastic demands computers operations citeseerx doisx de rigo rizzoli e soncinisessa r weber e zenesi p neurodynamic programming efficient management reservoir networks proceedings modsim international congress modelling simulation modsim international congress modelling simulation canberra australia modelling simulation society australia new zealand doizenodo isbn archived original august retrieved july damas salmeron diaz ortega j prieto olivares g genetic algorithms neurodynamic programming application water supply networks proceedings congress evolutionary computation congress evolutionary computation vol la jolla california us ieee pp doicec isbn deng g ferris mc neurodynamic programming fractionated radiotherapy planning optimization medicine springer optimization applications vol pp citeseerx doi isbn bozinovski selflearning system using secondary reinforcement r trappl ed cybernetics systems proceedings sixth european meeting cybernetics systems north holland pp isbn bozinovski modeling mechanisms cognitionemotion interaction artificial neural networks since archived march wayback machine procedia computer science p bozinovski bozinovska l selflearning agents connectionist theory emotion based crossbar value judgment cybernetics systems doi scid salimans ho j chen x sidor sutskever september evolution strategies scalable alternative reinforcement learning arxiv statml fp madhavan v conti e lehman j stanley ko clune j april deep neuroevolution genetic algorithms competitive alternative training deep neural networks reinforcement learning arxiv csne artificial intelligence evolve solve problems science aaas january archived original december retrieved february turchetti c stochastic models neural networks frontiers artificial intelligence applications knowledgebased intelligent engineering systems vol ios press isbn jospin lv laga h boussaid f buntine w bennamoun handson bayesian neural networksa tutorial deep learning users ieee computational intelligence magazine vol pp arxiv doimci issn x scid cang z wei gw july topologynet topology based deep convolutional multitask neural networks biomolecular property predictions plos computational biology e arxiv bibcodeplscbec doijournalpcbi issn pmc pmid de rigo castelletti rizzoli e soncinisessa r weber e january selective improvement technique fastening neurodynamic programming water resources network management pavel ztek ed proceedings th ifac world congress ifacpapersonline th ifac world congress vol prague czech republic ifac pp doicz hdl isbn archived original april retrieved december ferreira c designing neural networks using gene expression programming abraham b de baets kppen b nickolay eds applied soft computing technologies challenge complexity pdf springerverlag pp archived pdf original december retrieved october da xiurun g july improved psobased ann simulated annealing technique villmann ed new aspects neurocomputing th european symposium artificial neural networks vol elsevier pp doijneucom archived original april retrieved december wu j chen e may novel nonparametric regression ensemble rainfall forecasting using particle swarm optimization technique coupled artificial neural network wang h shen huang zeng z eds th international symposium neural networks isnn lecture notes computer science vol springer pp doi isbn archived original december retrieved january b ting qin zonghai chen haitao zhang sifu li wei xiang ming li learning algorithm cmac based rls pdf neural processing letters doibnepl scid archived pdf original april retrieved january ting qin haitao zhang zonghai chen wei xiang continuous cmacqrls systolic array pdf neural processing letters dois scid archived pdf original november retrieved january lecun boser b denker js henderson howard hubbard w et al backpropagation applied handwritten zip code recognition neural computation doineco scid yann lecun slides deep learning online archived april wayback machine hochreiter schmidhuber j november long shortterm memory neural computation doineco issn pmid scid sak h senior beaufays f long shortterm memory recurrent neural network architectures large scale acoustic modeling pdf archived original pdf april li x wu x october constructing long shortterm memory based deep recurrent neural networks large vocabulary speech recognition arxiv cscl fan qian xie f soong fk tts synthesis bidirectional lstm based recurrent neural networks proceedings annual conference international speech communication association interspeech retrieved june schmidhuber j deep learning scholarpedia bibcodeschpjs doischolarpedia zen h sak h unidirectional long shortterm memory recurrent neural network recurrent output layer lowlatency speech synthesis pdf googlecom icassp pp archived pdf original may retrieved june fan b wang l soong fk xie l photoreal talking head deep bidirectional lstm pdf proceedings icassp archived pdf original november retrieved june silver hubert schrittwieser j antonoglou lai guez et al december mastering chess shogi selfplay general reinforcement learning algorithm arxiv csai probst p boulesteix al bischl b february tunability importance hyperparameters machine learning algorithms j mach learn res scid zoph b le qv november neural architecture reinforcement learning arxiv cslg haifeng jin qingquan song xia hu autokeras efficient neural architecture system proceedings th acm sigkdd international conference knowledge discovery data mining acm arxiv archived original august retrieved august via autokerascom claesen de moor b hyperparameter machine learning arxiv cslg bibcodearxivc esch r functional approximation handbook applied mathematics springer us ed boston springer us pp doi isbn sarstedt moo e regression analysis concise guide market springer texts business economics springer berlin heidelberg pp doi isbn scid archived original march retrieved march tian j tan sun c zeng j jin december selfadaptive similaritybased fitness approximation evolutionary optimization ieee symposium series computational intelligence ssci pp doissci isbn scid archived original may retrieved march alaloul ws qureshi ah data processing using artificial neural networks dynamic data assimilation beating uncertainties doiintechopen isbn scid archived original march retrieved march pal roy r basu j bepari ms blind source separation review analysis international conference oriental cocosda held jointly conference asian spoken language evaluation ococosdacaslre ieee pp doiicsda isbn scid archived original march retrieved march zissis october cloud based architecture capable perceiving predicting multiple vessel behaviour applied soft computing doijasoc archived original july retrieved july sengupta n sahidullah md saha goutam august lung sound classification using cepstralbased statistical features computers biology medicine doijcompbiomed pmid choy christopher b et al drn unified approach single multiview object reconstruction archived july wayback machine european conference computer vision springer cham turek fred march introduction neural net machine vision vision systems design archived original may retrieved march maitra ds bhattacharya u parui sk august cnn based common approach handwritten character recognition multiple scripts th international conference document analysis recognition icdar pp doiicdar isbn scid archived original october retrieved march gessler j august sensor food analysis applying impedance spectroscopy artificial neural networks riunet upv archived original october retrieved october french j time travellers capm investment analysts journal doi scid roman balabin ekaterina lomakina neural network approach quantumchemistry data accurate prediction density functional theory energies j chem phys bibcodejchphgb doi pmid silver et al mastering game go deep neural networks tree pdf nature bibcodenaturs doinature pmid scid archived pdf original november retrieved january pasick march artificial intelligence glossary neural networks terms explained new york times issn archived original september retrieved april schechner june facebook boosts ai block terrorist propaganda wall street journal issn archived original may retrieved june ciaramella ciaramella introduction artificial intelligence data analysis generative ai intellisemantic editions isbn ganesan n application neural networks diagnosing cancer disease using demographic data international journal computer applications bibcodeijcazg doi bottaci l artificial neural networks applied outcome prediction colorectal cancer patients separate institutions pdf lancet lancet doisx pmid scid archived original pdf november retrieved may alizadeh e lyons sm castle jm prasad measuring systematic changes invasive cancer cell shape using zernike moments integrative biology doiciba pmid archived original may retrieved march lyons changes cell shape correlated metastatic potential murine biology open doibio pmc pmid nabian meidani h august deep learning accelerated reliability analysis infrastructure networks computeraided civil infrastructure engineering arxiv bibcodearxivn doimice scid nabian meidani h accelerating stochastic assessment postearthquake transportation network connectivity via machinelearningbased surrogates transportation board th annual meeting archived original march retrieved march daz e brotons v toms r september use artificial neural networks predict elastic settlement foundations soils inclined bedrock soils foundations bibcodesofoud doijsandf hdl issn tayebiyan mohammad ta ghazali ah mashohor artificial neural network modelling rainfallrunoff pertanika journal science technology archived original may retrieved may govindaraju rs april artificial neural networks hydrology preliminary concepts journal hydrologic engineering doiasce govindaraju rs april artificial neural networks hydrology ii hydrologic applications journal hydrologic engineering doiasce peres dj iuppa c cavallaro l cancelliere foti e october significant wave height record extension neural networks reanalysis wind data ocean modelling bibcodeocmodp doijocemod dwarakish gs rakshith natesan u review applications neural network coastal engineering artificial intelligent systems machine learning archived original august retrieved july ermini l catani f casagli n march artificial neural networks applied landslide susceptibility assessment geomorphology geomorphological hazard human impact mountain environments bibcodegeomoe doijgeomorph nix r zhang j may classification android apps malware using deep neural networks international joint conference neural networks ijcnn pp doiijcnn isbn scid detecting malicious urls systems networking group ucsd archived original july retrieved february homayoun ahmadzadeh hashemi dehghantanha khayami r dehghantanha conti dargahi eds botshark deep learning approach botnet traffic detection cyber threat intelligence advances information security vol springer international publishing pp doi isbn ghosh reilly january credit card fraud detection neuralnetwork proceedings twentyseventh hawaii international conference system sciences hicss vol pp doihicss isbn scid ananthaswamy april latest neural nets solve worlds hardest equations faster ever quanta magazine archived original may retrieved may ai cracked key mathematical puzzle understanding world mit technology review archived original may retrieved november caltech opensources ai solving partial differential equations infoq archived original january retrieved january nagy june variational quantum monte carlo method neuralnetwork ansatz open quantum systems physical review letters arxiv bibcodephrvlyn doiphysrevlett pmid scid yoshioka n hamazaki r june constructing neural stationary states open quantum manybody systems physical review b arxiv bibcodephrvbuy doiphysrevb scid hartmann mj carleo g june neuralnetwork approach dissipative quantum manybody dynamics physical review letters arxiv bibcodephrvlyh doiphysrevlett pmid scid vicentini f biella regnault n ciuti c june variational neuralnetwork ansatz steady states open quantum systems physical review letters arxiv bibcodephrvlyv doiphysrevlett pmid scid forrest md april simulation alcohol action upon detailed purkinje neuron model simpler surrogate model runs times faster bmc neuroscience dois pmc pmid wieczorek filipiak filipowska semantic imagebased profiling users interests neural networks studies semantic web emerging topics semantic technologies doi archived original may retrieved january merchant batzner schoenholz ss aykol cheon g cubuk ed december scaling deep learning materials discovery nature bibcodenaturm dois issn pmc pmid siegelmann h sontag e turing computability neural nets pdf appl math lett doif archived pdf original may retrieved january bains november analog computer trumps turing model ee times archived original may retrieved may balczar j july computational power neural networks kolmogorov complexity characterization ieee transactions information theory citeseerx doi b mackay dj information theory inference learning algorithms pdf cambridge university press isbn archived pdf original october retrieved june cover geometrical statistical properties systems linear inequalities applications pattern recognition pdf ieee transactions electronic computers ec ieee doipgec archived pdf original march retrieved march gerald f reproducibility experimental design machine learning audio multimedia data proceedings th acm international conference multimedia acm pp doi isbn scid stop tinkering start measuring predictable experimental design neural network experiments tensorflow meter archived original april retrieved march lee j xiao l schoenholz ss bahri novak r sohldickstein j et al wide neural networks depth evolve linear models gradient descent journal statistical mechanics theory experiment arxiv bibcodejsmtell doiabcb scid arthur jacot franck gabriel clement hongler neural tangent kernel convergence generalization neural networks pdf nd conference neural information processing systems neurips montreal canada archived pdf original june retrieved june xu zj zhang xiao training behavior deep neural network frequency domain gedeon wong k lee eds neural information processing lecture notes computer science vol springer cham pp arxiv doi isbn scid nasim rahaman aristide baratin devansh arpit felix draxler min lin fred hamprecht et al spectral bias neural networks pdf proceedings th international conference machine learning arxiv archived pdf original october retrieved june zhiqin john xu yaoyu zhang tao luo yanyang xiao zheng frequency principle fourier analysis sheds light deep neural networks communications computational physics arxiv bibcodeccophx doicicpoa scid tao luo zheng zhiqin john xu yaoyu zhang theory frequency principle general deep neural networks arxiv cslg xu zj zhou h may deep frequency principle towards understanding deeper learning faster proceedings aaai conference artificial intelligence arxiv doiaaaivi issn scid archived original october retrieved october parisi gi kemker r part jl kanan c wermter may continual lifelong learning neural networks review neural networks arxiv doijneunet issn pmid dean pomerleau knowledgebased training artificial neural networks autonomous robot driving dewdney ak april yes neutrons eyeopening tour twists turns bad science wiley p isbn nasa dryden flight center news room news releases nasa neural network project passes milestone archived april wayback machine nasagov retrieved november roger bridgmans defence neural networks archived original march retrieved july scaling learning algorithms towards ai lisa publications aigaion iroumontrealcacite web cs maint urlstatus link j felleman c van essen distributed hierarchical processing primate cerebral cortex cerebral cortex pp j weng natural artificial intelligence introduction computational brainmind archived may wayback machine bmi press isbn b edwards c june growing pains deep learning communications acm doi scid bitter lesson incompleteideasnet retrieved august cade metz may google built chips power ai bots wired archived original january retrieved march scaling learning algorithms towards ai pdf archived pdf original august retrieved july tahmasebi hezarkhani hybrid neural networksfuzzy logicgenetic algorithm grade estimation computers geosciences bibcodecgt doijcageo pmc pmid sun bookman b norori n hu q aellen fm faraci fd tzovara october addressing bias big data ai health care call open science patterns doijpatter pmc pmid b carina w october failing face value effect biased facial recognition technology racial discrimination criminal justice scientific social doissrvi issn b chang x september gender bias hiring analysis impact amazons recruiting algorithm advances economics management political sciences doi issn archived original december retrieved december kortylewski egger b schneider gerig morelforster vetter june analyzing reducing damage dataset bias face recognition synthetic data ieeecvf conference computer vision pattern recognition workshops cvprw pdf ieee pp doicvprw isbn scid archived pdf original may retrieved december b c e f huang advances artificial neural networks methodological development application algorithms doialgor issn b c e kariri e louati h louati masmoudi f exploring advancements future directions artificial neural networks text mining approach applied sciences doiapp issn b fuihoon nah f zheng r cai j siau k chen l july generative ai chatgpt applications challenges aihuman collaboration journal information technology case application doi issn dalle failures interesting thing ieee spectrum ieee archived original july retrieved december briot jp january artificial neural networks deep learning music generation history concepts trends neural computing applications dois issn chow ps july ghost hollywood machine emergent applications artificial intelligence film industry necsuseuropean journal media studies doimediarep issn yu x gao yang j sha l zhang et al june dynamic difficulty adjustment game ai video game deadend rd international conference information sciences interaction sciences ieee pp doiicicis isbn scid bibliography bhadeshia h k h neural networks materials science pdf isij international doiisijinternational bishop cm neural networks pattern recognition clarendon press isbn oclc borgelt c neurofuzzysysteme von den grundlagen knstlicher neuronaler netze zur kopplung mit fuzzysystemen vieweg isbn oclc cybenko g approximation superpositions sigmoidal function van schuppen jh ed mathematics control signals systems springer international pp pdf dewdney ak yes neutrons eyeopening tour twists turns bad science new york wiley isbn oclc duda ro hart pe stork dg pattern classification ed wiley isbn oclc egmontpetersen de ridder handels h image processing neural networks review pattern recognition citeseerx dois fahlman lebiere c cascadecorrelation learning architecture pdf archived original pdf may retrieved august created national science foundation contract number eet defense advanced projects agency dod arpa order contract fc gurney k introduction neural networks ucl press isbn oclc haykin ss neural networks comprehensive foundation prentice hall isbn oclc hertz j palmer rg krogh introduction theory neural computation addisonwesley isbn oclc information theory inference learning algorithms cambridge university press september bibcodeitilbookm isbn oclc kruse r borgelt c klawonn f moewes c steinbrecher held p computational intelligence methodological introduction springer isbn oclc lawrence j introduction neural networks design theory applications california scientific software isbn oclc masters signal image processing neural networks c sourcebook j wiley isbn oclc maurer h cognitive science integrative synchronization mechanisms cognitive neuroarchitectures modern connectionism crc press doi isbn scid ripley bd pattern recognition neural networks cambridge university press isbn siegelmann h sontag ed analog computation via neural networks theoretical computer science doi scid smith neural networks statistical modeling van nostrand reinhold isbn oclc wasserman pd advanced methods neural computing van nostrand reinhold isbn oclc wilson h artificial intelligence grey house publishing isbn external links listen article minutes audio file created revision article dated november reflect subsequent editsaudio help spoken articles brief introduction neural networks kriesel illustrated bilingual manuscript artificial neural networks topics far perceptrons backpropagation radial basis functions recurrent neural networks self organizing maps hopfield networks review neural networks materials science archived june wayback machine artificial neural networks tutorial three languages univ politcnica de madrid another introduction ann next generation neural networks archived january wayback machine google tech talks performance neural networks neural networks information archived july wayback machine sanderson g october neural network bluebrown archived original november via youtube links related articles vteartificial intelligence aihistory timelineconcepts parameter hyperparameter loss functions regression biasvariance tradeoff double descent overfitting clustering gradient descent sgd quasinewton method conjugate gradient method backpropagation attention convolution normalization batchnorm activation softmax sigmoid rectifier gating weight initialization regularization datasets augmentation prompt engineering reinforcement learning qlearning sarsa imitation policy gradient diffusion latent diffusion model autoregression adversary rag uncanny valley rlhf selfsupervised learning recursive selfimprovement reflection word embedding hallucination applications machine learning incontext learning artificial neural network deep learning language model large language model nmt reasoning language model intelligent agent artificial human companion artificial general intelligence agi implementationsaudiovisual alexnet wavenet human image synthesis hwr ocr speech synthesis ai elevenlabs speech recognition whisper facial recognition alphafold texttoimage models aurora dalle firefly flux ideogram imagen midjourney stable diffusion texttovideo models dream machine runway gen hailuo ai kling sora veo music generation suno ai udio text wordvec seqseq glove bert llama chinchilla ai palm gpt j chatgpt claude gemini chatbot grok lamda bloom project debater ibm watson ibm watsonx granite pangu deepseek qwen decisional alphago alphazero openai five selfdriving car muzero action selection autogpt robot control people alan turing warren sturgis mcculloch walter pitts john von neumann claude shannon marvin minsky john mccarthy nathaniel rochester allen newell cliff shaw herbert simon oliver selfridge frank rosenblatt bernard widrow joseph weizenbaum seymour papert seppo linnainmaa paul werbos jrgen schmidhuber yann lecun geoffrey hinton john hopfield yoshua bengio lotfi zadeh stephen grossberg alex graves andrew ng feifei li alex krizhevsky ilya sutskever demis hassabis david silver ian goodfellow andrej karpathy james goodnight architectures neural turing machine differentiable neural computer transformer vision transformer vit recurrent neural network rnn long shortterm memory lstm gated recurrent unit gru echo state network multilayer perceptron mlp convolutional neural network cnn residual neural network rnn highway network mamba autoencoder variational autoencoder vae generative adversarial network gan graph neural network gnn portals technology category artificial neural networks machine learning list companies projects vtecomplex systemsbackground emergence selforganization collective behavior social dynamics collective intelligence collective action collective consciousness selforganized criticality herd mentality phase transition agentbased modelling synchronization ant colony optimization particle swarm optimization swarm behaviour evolution adaptation artificial neural network evolutionary computation genetic algorithms genetic programming artificial life machine learning evolutionary developmental biology artificial intelligence evolutionary robotics evolvability game theory prisoners dilemma rational choice theory bounded rationality evolutionary game theory networks social network analysis smallworld networks centrality motifs graph theory scaling robustness systems biology dynamic networks adaptive networks nonlinear dynamics time series analysis ordinary differential equations phase space attractor population dynamics chaos multistability bifurcation coupled map lattices pattern formation reactiondiffusion systems partial differential equations dissipative structures percolation cellular automata spatial ecology selfreplication geomorphology systems theory homeostasis operationalization feedback selfreference goaloriented system dynamics sensemaking entropy cybernetics autopoiesis information theory computation theory vtecontrol theorybranches adaptive control control theory digital control energyshaping control fuzzy control hybrid control intelligent control model predictive control multivariable control neural control nonlinear control optimal control realtime control robust control stochastic control system properties bode plot block diagram closedloop transfer function controllability fourier transform frequency response laplace transform negative feedback observability performance positive feedback root locus ethod servomechanism signalflow graph state space representation stability theory steady state analysis design system dynamics transfer function digital control discretetime signal digital signal processing quantization real time software sampled data system identification ztransform advanced techniques artificial neural network coefficient diagram method control reconfiguration distributed parameter systems fractionalorder control fuzzy logic hinfinity loopshaping hankel singular value kalman filter kreners theorem least squares lyapunov stability minor loop feedback perceptual control theory state observer vector control controllers embedded controller closedloop controller leadlag compensator numerical control pid controller programmable logic controller control applications automation remote control distributed control system electric motors industrial control systems mechatronics motion control process control robotics supervisory control scada vteneuroscience outline history basicscience behavioral epigenetics behavioral genetics brain mapping brainreading cellular neuroscience computational neuroscience connectomics imaging genetics integrative neuroscience molecular neuroscience neural decoding neural engineering neuroanatomy neurobiology neurochemistry neuroendocrinology neurogenetics neuroinformatics neurometrics neuromorphology neurophysics neurophysiology systems neuroscience clinicalneuroscience behavioral neurology clinical neurophysiology epileptology neurocardiology neuroepidemiology neurogastroenterology neuroimmunology neurointensive care neurology neurooncology neuroophthalmology neuropathology neuropharmacology neuroprosthetics neuropsychiatry neuroradiology neurorehabilitation neurosurgery neurotology neurovirology nutritional neuroscience psychiatry cognitiveneuroscience affective neuroscience behavioral neuroscience chronobiology molecular cellular cognition motor control neurolinguistics neuropsychology sensory neuroscience social cognitive neuroscience interdisciplinaryfields consumer neuroscience cultural neuroscience educational neuroscience evolutionary neuroscience global neurosurgery neuroanthropology neural engineering neurobiotics neurocinema neurocriminology neuroeconomics neuroepistemology neuroesthetics neuroethics neuroethology neurohistory neurolaw neuromarketing neuromorphic engineering neuroscience music neurophenomenology neurophilosophy neuropolitics neurorobotics neurotheology paleoneurobiology social neuroscience concepts braincomputer interface development nervous system neural network artificial neural network biological detection theory intraoperative neurophysiological monitoring neurochip neurodegenerative disease neurodevelopmental disorder neurodiversity neurogenesis neuroimaging neuroimmune system neuromanagement neuromodulation neuroplasticity neurotechnology neurotoxin selfawareness category commons vteselfdriving cars selfdriving vehicles enabling technologiesoverview context history selfdriving cars impact selfdriving cars intelligent transportation system contextaware pervasive systems mobile computing smart connected products ubiquitous computing ambient intelligence internet things list selfdriving system suppliers sae levelshuman driver monitors driving environmentlevels lane departure warning system automatic parking automated emergency braking system collision avoidance system cruise control adaptive cruise control advanced driverassistance system driver drowsiness detection intelligent speed adaptation blind spot monitor system monitors driving environmentlevels automated lane keeping systems vehicular ad hoc network vv connected car automotive system vehiclescars vamp spirit berlin general motors env madeingermany waymo formerly google car tesla model autopilot lutz pathfinder avride honda legend buses commercial vehicles automated guideway transit cavforth parkshuttle navia shuttle nutonomy taxi freightliner inspiration driverless tractor selfdriving truck mobility service regulation legislation ieee p safe speed automotive common law automated lane keeping system unece regulation regulation eu liabilityselfdriving car liabilityenabling technologies radar laser lidar artificial neural network computer stereo vision image recognition dedicated shortrange communications realtime control system rfpro eye tracking radiofrequency identification automotive system organizations projects peopleorganizations projects events american center mobility davi european landrobot trial navlab darpa grand challenge vislab intercontinental autonomous challenge eureka prometheus project ieee intelligent transportation systems society people harold goddijn alberto broggi anthony levandowski authority control databases national germanyunited statesjapanczech republiclatviaisrael retrieved httpsenwikipediaorgwindexphptitleneuralnetworkmachinelearningoldid categories computational statisticsartificial neural networksclassification algorithmscomputational neurosciencemarket remathematical psychologymathematical quantitative methods economicsbioinspirationhidden categories cs errors isbn datecs long volume valuecs finnishlanguage sources fiwebarchive template wayback linkscs germanlanguage sources deall articles incomplete citationsarticles incomplete citations june cs maint urlstatusarticles short descriptionshort description matches wikidatause dmy dates march pages using multiple image auto scaled imageswikipedia articles needing clarification april wikipedia articles needing clarificationall articles unsourced statementsarticles unsourced statements october articles unsourced statements june articles lacking intext citations august articles lacking intext citationsarticles unsourced statements june articles unsourced statements september articles unsourced statements july articles failed verificationarticles failed verification may articles unsourced statements january articles specifically marked weaselworded phrases january articles haudio microformatsspoken articles page last edited june utc text available creative commons attributionsharealike license additional terms may apply using site agree terms use privacy policy wikipedia registered trademark wikimedia foundation inc nonprofit organization privacy policy wikipedia disclaimers contact wikipedia code conduct developers statistics cookie statement mobile view toggle table contents neural network machine learning add topic